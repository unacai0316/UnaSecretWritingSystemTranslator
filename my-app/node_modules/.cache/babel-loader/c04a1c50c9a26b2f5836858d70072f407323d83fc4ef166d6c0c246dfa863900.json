{"ast":null,"code":"'use strict';\n\nconst mdbg = require('mdbg');\nconst tokenizer = async (text, opts = {}) => {\n  const list = [];\n  let index = 0;\n  while (index < text.length) {\n    let count = text.length - index;\n    let wordFound = false;\n    while (count >= 0) {\n      const word = text.substr(index, count);\n      try {\n        const entry = await mdbg.getByHanzi(word);\n        index += count - 1;\n        if (list.length === 0 || typeof list[list.length - 1] === 'string' || !opts.spaces) {\n          list.push(entry);\n        } else {\n          list.push(' ', entry);\n        }\n        wordFound = true;\n        break;\n      } catch (err) {\n        if (err.type !== 'NotFoundError') console.error(err);\n      }\n      count--;\n    }\n    if (!wordFound && opts.everything) {\n      if (typeof list[list.length - 1] === 'string') {\n        list[list.length - 1] += text[index];\n      } else {\n        list.push(text[index]);\n      }\n    }\n    index++;\n  }\n  return list;\n};\nmodule.exports = tokenizer;\nmodule.exports.init = mdbg.init;","map":{"version":3,"names":["mdbg","require","tokenizer","text","opts","list","index","length","count","wordFound","word","substr","entry","getByHanzi","spaces","push","err","type","console","error","everything","module","exports","init"],"sources":["/Users/tsaiyunzhen/my-react-app/my-app/node_modules/hanzi-tokenizer/index.js"],"sourcesContent":["'use strict'\n\nconst mdbg = require('mdbg')\n\nconst tokenizer = async (text, opts = {}) => {\n\tconst list = []\n\tlet index = 0\n\twhile (index < text.length) {\n\t\tlet count = text.length - index\n\t\tlet wordFound = false\n\t\twhile (count >= 0) {\n\t\t\tconst word = text.substr(index, count)\n\t\t\ttry {\n\t\t\t\tconst entry = await mdbg.getByHanzi(word)\n\t\t\t\tindex += count - 1\n\t\t\t\tif (list.length === 0 || typeof list[list.length - 1] === 'string' || !opts.spaces) {\n\t\t\t\t\tlist.push(entry)\n\t\t\t\t} else {\n\t\t\t\t\tlist.push(' ', entry)\n\t\t\t\t}\n\t\t\t\twordFound = true\n\t\t\t\tbreak\n\t\t\t} catch (err) {\n\t\t\t\tif (err.type !== 'NotFoundError') console.error(err)\n\t\t\t}\n\t\t\tcount--\n\t\t}\n\t\tif (!wordFound && opts.everything) {\n\t\t\tif (typeof list[list.length - 1] === 'string') {\n\t\t\t\tlist[list.length - 1] += text[index]\n\t\t\t} else {\n\t\t\t\tlist.push(text[index])\n\t\t\t}\n\t\t}\n\t\tindex++\n\t}\n\treturn list\n}\n\nmodule.exports = tokenizer\nmodule.exports.init = mdbg.init\n"],"mappings":"AAAA,YAAY;;AAEZ,MAAMA,IAAI,GAAGC,OAAO,CAAC,MAAM,CAAC;AAE5B,MAAMC,SAAS,GAAG,MAAAA,CAAOC,IAAI,EAAEC,IAAI,GAAG,CAAC,CAAC,KAAK;EAC5C,MAAMC,IAAI,GAAG,EAAE;EACf,IAAIC,KAAK,GAAG,CAAC;EACb,OAAOA,KAAK,GAAGH,IAAI,CAACI,MAAM,EAAE;IAC3B,IAAIC,KAAK,GAAGL,IAAI,CAACI,MAAM,GAAGD,KAAK;IAC/B,IAAIG,SAAS,GAAG,KAAK;IACrB,OAAOD,KAAK,IAAI,CAAC,EAAE;MAClB,MAAME,IAAI,GAAGP,IAAI,CAACQ,MAAM,CAACL,KAAK,EAAEE,KAAK,CAAC;MACtC,IAAI;QACH,MAAMI,KAAK,GAAG,MAAMZ,IAAI,CAACa,UAAU,CAACH,IAAI,CAAC;QACzCJ,KAAK,IAAIE,KAAK,GAAG,CAAC;QAClB,IAAIH,IAAI,CAACE,MAAM,KAAK,CAAC,IAAI,OAAOF,IAAI,CAACA,IAAI,CAACE,MAAM,GAAG,CAAC,CAAC,KAAK,QAAQ,IAAI,CAACH,IAAI,CAACU,MAAM,EAAE;UACnFT,IAAI,CAACU,IAAI,CAACH,KAAK,CAAC;QACjB,CAAC,MAAM;UACNP,IAAI,CAACU,IAAI,CAAC,GAAG,EAAEH,KAAK,CAAC;QACtB;QACAH,SAAS,GAAG,IAAI;QAChB;MACD,CAAC,CAAC,OAAOO,GAAG,EAAE;QACb,IAAIA,GAAG,CAACC,IAAI,KAAK,eAAe,EAAEC,OAAO,CAACC,KAAK,CAACH,GAAG,CAAC;MACrD;MACAR,KAAK,EAAE;IACR;IACA,IAAI,CAACC,SAAS,IAAIL,IAAI,CAACgB,UAAU,EAAE;MAClC,IAAI,OAAOf,IAAI,CAACA,IAAI,CAACE,MAAM,GAAG,CAAC,CAAC,KAAK,QAAQ,EAAE;QAC9CF,IAAI,CAACA,IAAI,CAACE,MAAM,GAAG,CAAC,CAAC,IAAIJ,IAAI,CAACG,KAAK,CAAC;MACrC,CAAC,MAAM;QACND,IAAI,CAACU,IAAI,CAACZ,IAAI,CAACG,KAAK,CAAC,CAAC;MACvB;IACD;IACAA,KAAK,EAAE;EACR;EACA,OAAOD,IAAI;AACZ,CAAC;AAEDgB,MAAM,CAACC,OAAO,GAAGpB,SAAS;AAC1BmB,MAAM,CAACC,OAAO,CAACC,IAAI,GAAGvB,IAAI,CAACuB,IAAI","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}